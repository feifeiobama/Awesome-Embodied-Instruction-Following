@String(ICLR  = {ICLR})
@String(ICML  = {ICML})
@String(NIPS  = {NeurIPS})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(CVPRW = {CVPR Workshop})
@String(EMNLP = {EMNLP})
@String(ACLF  = {Findings of ACL})
@String(RAL   = {RA-L})
@String(IROS  = {IROS})
@String(AAAI  = {AAAI})
@String(ICPR  = {ICPR})


@inproceedings{shridhar2020alfred,
  title={{ALFRED}: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  author={Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  booktitle=CVPR,
  pages={10740--10749},
  year={2020}
}

# ABP
@inproceedings{kim2021agent,
  title={Agent with the Big Picture: Perceiving Surroundings for Interactive Instruction Following},
  author={Kim, Byeonghwi and Bhambri, Suvaansh and Singh, Kunal Pratap and Mottaghi, Roozbeh and Choi, Jonghyun},
  booktitle=CVPRW,
  year={2021}
}

# MOCA
@inproceedings{singh2021factorizing,
  title={Factorizing Perception and Policy for Interactive Instruction Following},
  author={Singh, Kunal Pratap and Bhambri, Suvaansh and Kim, Byeonghwi and Mottaghi, Roozbeh and Choi, Jonghyun},
  booktitle=ICCV,
  pages={1888--1897},
  year={2021}
}

# E.T.
@inproceedings{pashevich2021episodic,
  title={Episodic Transformer for Vision-and-Language Navigation},
  author={Pashevich, Alexander and Schmid, Cordelia and Sun, Chen},
  booktitle=ICCV,
  pages={15942--15952},
  year={2021}
}

# LWIT
@inproceedings{suganuma2021look,
  title={Look Wide and Interpret Twice: Improving Performance on Interactive Instruction-following Tasks},
  author={Suganuma, Masanori and Okatani, Takayuki and others},
  booktitle=IJCAI,
  pages={923--930},
  year={2021}
}

# HiTUT
@inproceedings{zhang2021hierarchical,
  title={Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring},
  author={Zhang, Yichi and Chai, Joyce},
  booktitle=ACLF,
  pages={4202--4213},
  year={2021}
}

# EmBERT
@article{suglia2021embodied,
  title={Embodied {BERT}: A Transformer Model for Embodied, Language-guided Visual Task Completion},
  author={Suglia, Alessandro and Gao, Qiaozi and Thomason, Jesse and Thattai, Govind and Sukhatme, Gaurav},
  journal={arXiv preprint arXiv:2108.04927},
  year={2021}
}

# LAV
@article{nottingham2021modular,
  title={Modular Framework for Visuomotor Language Grounding},
  author={Nottingham, Kolby and Liang, Litian and Shin, Daeyun and Fowlkes, Charless C and Fox, Roy and Singh, Sameer},
  journal={arXiv preprint arXiv:2109.02161},
  year={2021}
}

@inproceedings{min2022film,
  title={{FILM}: Following Instructions in Language with Modular Methods},
  author={Min, So Yeon and Chaplot, Devendra Singh and Ravikumar, Pradeep Kumar and Bisk, Yonatan and Salakhutdinov, Ruslan},
  booktitle=ICLR,
  year={2022}
}

# MAT
@inproceedings{ishikawa2022moment,
  title={Moment-based Adversarial Training for Embodied Language Comprehension},
  author={Ishikawa, Shintaro and Sugiura, Komei},
  booktitle=ICPR,
  pages={4139--4145},
  year={2022}
}

# M-Track
@inproceedings{song2022one,
  title={One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones},
  author={Song, Chan Hee and Kil, Jihyung and Pan, Tai-Yu and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle=CVPR,
  pages={15482--15491},
  year={2022}
}

# EPA
@inproceedings{liu2022planning,
  title={A Planning based Neural-Symbolic Approach for Embodied Instruction Following},
  author={Liu, Xiaotian and Palacios, Hector and Muise, Christian},
  booktitle=CVPRW,
  year={2022}
}

# AMSLAM
@inproceedings{jia2022learning,
  title={Learning to Act with Affordance-Aware Multimodal Neural {SLAM}},
  author={Jia, Zhiwei and Lin, Kaixiang and Zhao, Yizhou and Gao, Qiaozi and Thattai, Govind and Sukhatme, Gaurav S},
  booktitle=IROS,
  pages={5877--5884},
  year={2022}
}

# HLSM
@inproceedings{blukis2022persistent,
  title={A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution},
  author={Blukis, Valts and Paxton, Chris and Fox, Dieter and Garg, Animesh and Artzi, Yoav},
  booktitle=CoRL,
  pages={706--717},
  year={2022}
}

# LGS-RPA
@article{murray2022following,
title={Following Natural Language Instructions for Household Tasks with Landmark Guided Search and Reinforced Pose Adjustment},
  author={Murray, Michael and Cakmak, Maya},
  journal=RAL,
  volume={7},
  number={3},
  pages={6870--6877},
  year={2022}
}

@article{inoue2022prompter,
  title={Prompter: Utilizing Large Language Model Prompting for a Data Efficient Embodied Instruction Following},
  author={Inoue, Yuki and Ohashi, Hiroki},
  journal={arXiv preprint arXiv:2211.03267},
  year={2022}
}

@inproceedings{song2023llm,
  title={{LLM-Planner}: Few-Shot Grounded Planning for Embodied Agents with Large Language Models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle=ICCV,
  pages={2998--3009},
  year={2023}
}

# CAPEAM
@inproceedings{kim2023context,
  title={Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents},
  author={Kim, Byeonghwi and Kim, Jinyeon and Kim, Yuyeong and Min, Cheolhong and Choi, Jonghyun},
  booktitle=ICCV,
  pages={10936--10946},
  year={2023}
}

@inproceedings{yang2023lacma,
  title={{LACMA}: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following},
  author={Yang, Cheng-Fu and Chen, Yen-Chun and Yang, Jianwei and Dai, Xiyang and Yuan, Lu and Wang, Yu-Chiang and Chang, Kai-Wei},
  booktitle=EMNLP,
  pages={1203--1217},
  year={2023}
}

@article{chen2023robogpt,
  title={RoboGPT: An Intelligent Agent of Making Embodied Long-Term Decisions for Daily Instruction Tasks},
  author={Chen, Yaran and Cui, Wenbo and Chen, Yuanwen and Tan, Mining and Zhang, Xinyao and Zhao, Dongbin and Wang, He},
  journal={arXiv preprint arXiv:2311.15649},
  year={2023}
}

# MCR-Agent
@inproceedings{bhambri2024multi,
  title={Multi-Level Compositional Reasoning for Interactive Instruction Following},
  author={Bhambri, Suvaansh and Kim, Byeonghwi and Choi, Jonghyun},
  booktitle=AAAI,
  year={2024}
}